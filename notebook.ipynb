{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating American Community Survey Data to arbitrary geographies\n",
    "\n",
    "**TLDR:** This notebook provides reusable code to aggregate ACS data to any arbitrary geography, assuming you've already done the work to map Census Blocks to the aggregate geography. John Keefe has done that work for [NYC police precincts](https://johnkeefe.net/nyc-police-precinct-and-census-data), [Chicago police districts](https://johnkeefe.net/chicago-race-and-ethnicity-data-by-police-district), and [Washington, DC police zones](https://johnkeefe.net/race-and-ethnicity-data-by-washington-dc-police-zones).\n",
    "\n",
    "-----\n",
    "\n",
    "[John Keefe](https://johnkeefe.net/) has recently been producing demographic profiles of policing geographies. ([NYC police precincts](https://johnkeefe.net/nyc-police-precinct-and-census-data) | [Chicago police districts](https://johnkeefe.net/chicago-race-and-ethnicity-data-by-police-district) | [Washington, DC police zones](https://johnkeefe.net/race-and-ethnicity-data-by-washington-dc-police-zones)). (Since I'm in Chicago, I'll use \"district\" as the catchall for \"policing geography\")\n",
    "\n",
    "His is a commonly used method for doing this: compare US Census block maps to GIS maps for the districts, making a crosswalk which indicates which blocks are in which district, and then adding up the data for those blocks. Census blocks are the smallest unit of geography used for tabulating Census data, and they are generally small enough that they fall within other geographies, although, in his process, John has had to resolve cases where districts cross through blocks. (Only a few, and he details his decisions in the posts linked above.)\n",
    "\n",
    "Unfortunately, the Census only publishes block-level data every ten years, which means that these demographics are now ten years out of date. Also, they are limited to the data collected for the decennial census: sex, age, race, ethnicity (hispanic/latino or not), and a few things about housing and how people living in the same home are related to each other. \n",
    "\n",
    "The Census publishes another data product, the American Community Survey (ACS), each year, but it doesn't tabulate data at the block level. (The ACS also includes data about education and income among other topics beyond what's covered in the Decennial Census.)  It would be great to use this more recent, and more expansive data, but how can we deal with the lack of block-level data?\n",
    "\n",
    "One might simply use John's process with block groups or tracts. Undoubtedly, there would be more cases where those Census geographies are split by districts. John's approach to researching each split and making a judgment call assigning it to a single district would be time consuming, and would probably lead to distortions of the data. \n",
    "\n",
    "Of course, this isn't a completely new problem. The general solution is to compute a weighting factor for each part of the split Census geography in relation to the districts or other geographies. Then, when adding up estimates from the Census geographies, allocate the estimates for split geographies based on the weighting factor.\n",
    "\n",
    "An obvious approach to weighting is by area, but that assumes that the data used to produce the Census estimates is evenly distributed, which is generally not the case. A little better approach is to divide the population of the blocks in each split by the total population of the geography. As with area, this assumes that demographics of people are evenly spread through the geography, but there's a limit to what we can do with available data, so it's a compromise we have to accept.  \n",
    "\n",
    "Since the two main things that the Census counts are people and housing units, it's also common to provide a second factor based on the ratio of housing units in each split to the whole, and to choose between the \"population weight factor\" and the \"housing unit weight factor\" based on what kind of estimates you're trying to aggregate.\n",
    "\n",
    "*Warning:* There's a risk that using 2010 block population and housing unit data to compute weighting factors, and then using those to allocate 2018 ACS data, will also produce distortions. For example, Chicago's Robert Taylor Homes were demolished in 2007, so the 2010 base population and housing unit counts for blocks there are zero or close to zero. By 2018, those blocks have begun redeveloping. Of course, the ACS is already a survey which produces imprecise estimates, so the real lesson is simply that you should use care when writing or talking about analysis based on this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/germuska/Library/Caches/pypoetry/virtualenvs/acs-aggregate-U2DmabzB-py3.7/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# Basic boilerplate\n",
    "import pandas as pd\n",
    "import cenpy\n",
    "import os\n",
    "import re\n",
    "\n",
    "# set this environment variable, or edit this cell to configure your own Census API key if necessary\n",
    "CENSUS_API_KEY = os.environ.get('CENSUS_API_KEY') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Utility functions. You probably won't use these directly.\n",
    "#\n",
    "\n",
    "def _block_id_substr(block_id,substr_len):\n",
    "    \"\"\"Given a Census block identifier, return the beginning `substr_len` characters.\n",
    "       Use 2 for state, 5 for (state and county), 11 for tract, or 12 for block group. \n",
    "       Given the structure of block IDs, no other value for substr_len is appropriate,\n",
    "       but that's on you.\n",
    "    \"\"\"\n",
    "    if type(block_id) != str:\n",
    "        block_id = str(block_id).zfill(15) # in case they were read in as numbers instead of strings. \n",
    "    if 'US' in block_id:\n",
    "        block_id = block_id.split('US')[1]\n",
    "    if len(block_id) == 15 and block_id.isdigit():\n",
    "        return block_id[0:substr_len]\n",
    "    raise ValueError(f\"Invalid block ID {block_id}\")\n",
    "        \n",
    "def tract_id_from_block_id(block_id):\n",
    "    return _block_id_substr(block_id,11)\n",
    "\n",
    "def bg_id_from_block_id(block_id):\n",
    "    return _block_id_substr(block_id,12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0.5: Add population and housing unit counts to a block assignment file.\n",
    "\n",
    "John Keefe's process begins with creating a \"Rosetta Stone\" file, which we could also call a \"block assignment file\". For Chicago, this file is called `chicago_2010blocks_2020policedistricts_key.csv`. His data files (e.g. `chicago_2010blocks_2020policedistricts_population.csv`) don't have housing unit estimates, and in any case, for other aggregation projects, those won't exist, so let's begin by adding these base numbers to the rosetta stone/block assignment file.\n",
    "\n",
    "This also serves as a generalized tool which could be used to create his data file, by passing different variables as the `api_vars` argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_data_for_county(state, county,api_vars=None):\n",
    "    \"\"\"Given state and county FIPS codes, return 2010 Decennial Census data for all Census blocks in that county. By default, this function\n",
    "    will return total housing units and total population from the 2010 Decennial Census, but, optionally, you can provide a different list of\n",
    "    valid variables for the 2010 Decennial Census SF1 API. (DECENNIALSF12010 in cenpy terms)\n",
    "    \"\"\"\n",
    "    predicate_xref = {\n",
    "        'int': int,\n",
    "        'float': float\n",
    "    }\n",
    "    if api_vars is None:\n",
    "        api_vars = ['H001001','P001001']\n",
    "    api_con = cenpy.products.APIConnection('DECENNIALSF12010',apikey=CENSUS_API_KEY)\n",
    "    df = api_con.query(cols=api_vars,geo_unit='block',geo_filter={'state': state, 'county': county})    \n",
    "    def concat_geoid(row):\n",
    "        parts = [row.loc[c] for c in ['state', 'county', 'tract', 'block']]\n",
    "        return ''.join(parts)\n",
    "    df['geoid'] = df.apply(concat_geoid,result_type='expand',axis=1)\n",
    "    predicates = api_con.variables['predicateType']\n",
    "    # cenpy returns numeric values as strings so we need to convert them\n",
    "    # use the API's predicateType value to distinguish between int and float values.\n",
    "    for var in api_vars:\n",
    "        if var == 'P001001': # Census API incorrectly returns this as NaN :'(\n",
    "            vtype = 'int'\n",
    "        else:\n",
    "            vtype = predicates.loc[var]\n",
    "        df[var] = df[var].astype(predicate_xref.get(vtype,'object')) \n",
    "    return df.set_index('geoid').drop(['state','county','tract','block'],axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_unique_counties(id_list):\n",
    "    \"\"\"Given a list of tract, block group, or block IDs, return a DataFrame representing the unique set of \n",
    "    state/counties which includes all of the IDs. This can be done because the first five digits\n",
    "    of these identifiers are built from the two-digit state FIPS code and the three-digit county FIPS code.\n",
    "    \n",
    "    The input can be a pandas Series or Index or a simple list, or anything, really, that can be made into a pandas Series.\n",
    "    Note that the data in the `id_list` argument should be strings, not numbers.\n",
    "    \n",
    "    The returned DataFrame will have two columns, `state` and `county`.\n",
    "    \n",
    "    This is needed because the Census API doesn't support querying a list of tracts, block groups, or blocks. Instead, one must ask\n",
    "    for \"all tracts (etc.) in a given state/county\".\n",
    "    \"\"\"\n",
    "    id_series = pd.Series(id_list)\n",
    "    state_series = id_series.apply(lambda x: x[0:2])\n",
    "    county_series = id_series.apply(lambda x: x[2:5])\n",
    "    return pd.DataFrame({'state': state_series, 'county': county_series}).drop_duplicates()\n",
    "    \n",
    "def add_block_data(df, vars=None):\n",
    "    \"\"\"Given a DataFrame `df` with an index of 15-char block geoIDs, return a dataframe with the \n",
    "    same data plus columns with the Decennial Census SF1 data for the given `vars`.  If no vars are \n",
    "    specified, return total population (P001001) and total housing units (H001001)\"\"\"\n",
    "    # block queries must be by state and county, so figure out which states and counties we need to deal with.\n",
    "    state_county = _extract_unique_counties(df.index)\n",
    "    blocks = []\n",
    "    for idx,row in state_county.iterrows():\n",
    "        blocks.append(block_data_for_county(row['state'], row['county']))\n",
    "    block_df = pd.concat(blocks)\n",
    "    return df.join(block_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: add the base population and housing unit counts to the block assignment file\n",
    "\n",
    "1. Read in John's \"rosetta stone\" block assignment file, `chicago_2010blocks_2020policedistricts_key.csv`. Make sure that the block IDs are treated as strings to avoid problems with states that have leading '0' in their FIPS codes.\n",
    "2. Use `add_block_data` to get the data needed for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist_num</th>\n",
       "      <th>H001001</th>\n",
       "      <th>P001001</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEOID10</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170318105015005</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170318105015000</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170318105023016</th>\n",
       "      <td>31</td>\n",
       "      <td>100</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170317709014009</th>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170318105012006</th>\n",
       "      <td>31</td>\n",
       "      <td>73</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dist_num  H001001  P001001\n",
       "GEOID10                                    \n",
       "170318105015005        31        1        2\n",
       "170318105015000        31        0        0\n",
       "170318105023016        31      100      466\n",
       "170317709014009        31       30       82\n",
       "170318105012006        31       73      189"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baf = pd.read_csv('chicago_2010blocks_2020policedistricts_key.csv',dtype={'GEOID10': 'object'})\n",
    "blocks_with_data = add_block_data(baf.set_index('GEOID10'))\n",
    "blocks_with_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create a tract-level or block-group level crosswalk with weighting factors\n",
    "\n",
    "The `blocks_to_tracts` function assumes you have a table where each row represents a Census block, and which has at least four columns:\n",
    "\n",
    "* Block ID: This can be either a 15-digit \"short geoid\" (eg _170318369002003_) or a longer block geoid of the kind returned from the Census Bureau API (eg _1000000US170318369002003_).\n",
    "* Total housing units for the block\n",
    "* Total population for the block\n",
    "* an identifier for the geography to which you've assigned the block.\n",
    "\n",
    "If you have the assignments but not the population and housing units, see above for how to add those values. And, technically, this can be used with only one of the two total counts, although we recommend computing both population and housing weighting factors.\n",
    "\n",
    "More technical details to using this function: you must read your block assignment file into a `pandas DataFrame` and set the DataFrame's index to the block ID column. The other columns can have any names you want: you specify the names when you invoke this function. \n",
    "\n",
    "The return is a DataFrame which typically has four columns, assuming that both `pop_column` and `hu_column` were specified: \n",
    "\n",
    "* `tract`: the tract ID which is in, or partially in, the aggregate geography.\n",
    "* _`[aggregate_id]`_: a column which preserves your aggregate geography identifiers, which has the same name as the input `DataFrame`\n",
    "* `hufactor`: a number from 0 to 1 representing the proportion of housing units in the whole tract which are in the intersection of this tract and aggregate geography (if no housing column is specified, this column will not be in the return DataFrame)\n",
    "* `pfactor`: a number from 0 to 1 representing the proportion of population in the whole tract which are in the intersection of this tract and aggregate geography (if no population column is specified, this column will not be in the return DataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blocks_to_tracts(df, group_column, pop_column=None, hu_column=None, na_to_zero=True):\n",
    "    \"\"\"Given a dataframe that maps blocks to some other geography, return a new data frame that contains\n",
    "    weighting factors for the distribution of population and housing units for tracts related to that other \n",
    "    geography.\n",
    "    \n",
    "    Arguments:\n",
    "    * df: a pandas DataFrame. This DataFrame *must* have a specific index, Census block identifiers. These can \n",
    "    either be 15-digit strings or \"long\" block identifiers, e.g. either '170318105015005' or '1000000US170318105015005'\n",
    "    After the first argument, a DataFrame, the next three arguments should be the names of the columns in the given dataframe which have that data. \n",
    "    * group_column: a column of arbitrary identifiers which will be used to determine which tracts are \n",
    "                    contained or partially contained within that geography. \n",
    "    * hu_column: If not None, this should be the name of a DataFrame column containing the total number of housing units \n",
    "                 for that block. \n",
    "    * pop_column: If not None, this should be the name of a DataFrame colum containing the total number of people for \n",
    "                  that block.\n",
    "\n",
    "    An optional kwarg, `na_to_zero` can be passed to control how this function handles division-by-zero --\n",
    "    that is, the cases when there are no housing units or no population in an entire tract. This would result in \n",
    "    `hufactor` or `pfactor` values of NaN, which would lead to unexpected behavior if one of those factors were \n",
    "    used in allocating estimates across split tracts. Therefore, by default, this function replaces NaN values \n",
    "    with zero. Set `na_to_zero=False` to have the returned data frame preserve NA values.\n",
    "\n",
    "    The returned dataframe will have the following columns. The first two are part of a multi-index.\n",
    "    * tract (index) - the first 11 digits of the block IDs, appearing once if the tract is completely contained \n",
    "              within the grouping geography, or more than once if blocks in the tract are split across \n",
    "              grouping geographies\n",
    "    * [group_column] (index) indicating the aggregate\n",
    "              geography which contains some or all of the tract\n",
    "    * hufactor - (if hu_column was specified) a number from 0 to 1 indicating the fraction of housing units in the whole tract which are \n",
    "                 in the portion of the tract which is within this aggregate geography\n",
    "    * [hu_column] - (if hu_column was specified) a column with the same name as the input \"hu_column\" with the value of the\n",
    "                    sum of values for that column for the given tract or part of a tract\n",
    "    * pfactor -  (if pop_column was specified) a number from 0 to 1 indicating the fraction of population in the whole tract which are \n",
    "                 in the portion of the tract which is within this aggregate geography\n",
    "    * [pop_column] - (if pop_column was specified) a column with the same name as the input \"pop_column\" with the value of the\n",
    "                     sum of values for that column for the given tract or part of a tract\n",
    "                 \n",
    "    This can then be used to allocate tract-level estimates across aggregate geographies based on whether \n",
    "    the estimate being aggregated is of people or of housing units. If aggregating estimates with a universe\n",
    "    other than total population or total housing units, be aware that the subset in that universe may not be\n",
    "    equally distributed across blocks. In theory, one could use the same method with other block-level \n",
    "    statistics (like population above or below a certain age) to get other allocation factors, but that's \n",
    "    reserved for future work.\n",
    "    \"\"\"\n",
    "    by_group = _factorizer(df, group_column, tract_id_from_block_id, pop_column=pop_column, hu_column=hu_column, na_to_zero=na_to_zero)\n",
    "    return by_group.reset_index().rename(columns={'census_geog': 'tract'}).set_index(['tract', group_column])\n",
    "\n",
    "def blocks_to_bgs(df, group_column, pop_column=None, hu_column=None, na_to_zero=True):\n",
    "    by_group = _factorizer(df, group_column, bg_id_from_block_id, pop_column=pop_column, hu_column=hu_column, na_to_zero=na_to_zero)\n",
    "    return by_group.reset_index().rename(columns={'census_geog': 'block group'}).set_index(['block group', group_column])\n",
    "    \n",
    "def _factorizer(df, group_column, idfunc, pop_column=None, hu_column=None, na_to_zero=True):\n",
    "    \"Utility function representing the common behavior independent of census geography type\"\n",
    "    index_col_name = df.index.name\n",
    "    if index_col_name is None: index_col_name = 'index' # how Pandas names anon indices\n",
    "    df = df.reset_index()\n",
    "    df['census_geog'] = df[index_col_name].apply(idfunc)\n",
    "    sum_cols = []\n",
    "    if hu_column:\n",
    "        sum_cols.append(hu_column)\n",
    "    if pop_column:\n",
    "        sum_cols.append(pop_column)\n",
    "    summed = df.groupby(['census_geog'])[sum_cols].sum()\n",
    "    by_group = df.groupby(['census_geog',group_column])[sum_cols].sum()\n",
    "    by_group = by_group.reset_index(group_column) # push \n",
    "    if hu_column:\n",
    "        by_group['hufactor'] =  by_group[hu_column] / summed[hu_column]\n",
    "    if pop_column:\n",
    "        by_group['pfactor'] = by_group[pop_column] / summed[pop_column]\n",
    "    if na_to_zero:\n",
    "        by_group = by_group.fillna(0)\n",
    "    return by_group\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: compute weighting factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>H001001</th>\n",
       "      <th>P001001</th>\n",
       "      <th>hufactor</th>\n",
       "      <th>pfactor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tract</th>\n",
       "      <th>dist_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">17031030200</th>\n",
       "      <th>20</th>\n",
       "      <td>88</td>\n",
       "      <td>130</td>\n",
       "      <td>0.032282</td>\n",
       "      <td>0.024213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2638</td>\n",
       "      <td>5239</td>\n",
       "      <td>0.967718</td>\n",
       "      <td>0.975787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17031081403</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">17031150501</th>\n",
       "      <th>16</th>\n",
       "      <td>1449</td>\n",
       "      <td>3643</td>\n",
       "      <td>0.997934</td>\n",
       "      <td>0.998629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.001371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      H001001  P001001  hufactor   pfactor\n",
       "tract       dist_num                                      \n",
       "17031030200 20             88      130  0.032282  0.024213\n",
       "            24           2638     5239  0.967718  0.975787\n",
       "17031081403 1               0        0  0.000000  0.000000\n",
       "17031150501 16           1449     3643  0.997934  0.998629\n",
       "            31              3        5  0.002066  0.001371"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `blocks_with_data` was created in an example above\n",
    "weight_factors = blocks_to_tracts(blocks_with_data,'dist_num',pop_column='P001001',hu_column='H001001')\n",
    "\n",
    "# test to see some split tracts. \n",
    "# For tracts with non-zero factors, the factors should add up to 1\n",
    "# for tracts with zero values for either/both factors, those are cases where all blocks in those tracts have\n",
    "# no population or housing; there are corresponding values for the same tract \n",
    "# with a 1.0 factor which are hidden by the dataframe filter condition.\n",
    "weight_factors[weight_factors['pfactor'] < 1].sort_values('tract').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you plan to work with these geographies a lot, save this file to a CSV. When you load it, remember to set the (multi-)index to the first two columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Fetch data for current ACS tables, aggregated to your geographies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(API in progress)\n",
    "\n",
    "To fetch data, you must specify the ACS data product and variables from that product. Because we use `cenpy` \"under the hood,\" data products are specified using `cenpy`'s codes. (You can learn more about these products from the [API documentation](https://api.census.gov/data/2018/acs/acs5.html)). One product, the _Comparison Profiles_, is not supported because it is not published at the Census tract level.\n",
    "\n",
    "Here are examples, other years are available.\n",
    "\n",
    "* `ACSDT5Y2018`: Detailed Tables (>64,000 [variables](https://api.census.gov/data/2018/acs/acs5/variables.html))\n",
    "* `ACSDP5Y2018`: Data Profiles (>2,400 [variables](https://api.census.gov/data/2018/acs/acs5/profile/variables.html))\n",
    "* `ACSST5Y2018`: Subject Tables (>66,000 [variables](https://api.census.gov/data/2018/acs/acs5/subject/variables.html))\n",
    "\n",
    "It's up to you to make sure that the variables passed in `var_list` are actually available in ACS product represented by `acs_product`. Making it easier to find specific variables is outside the scope of this service.\n",
    "\n",
    "Also, note that at this time, the aggregation does not handle  aggregating percentages, margins of error, or median values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_data_for_county(state, county, acs_product, var_list, census_geog='tract'):\n",
    "    \"\"\"Given state and county FIPS codes, return 2010 Decennial Census data for all Census blocks in that county. By default, this function\n",
    "    will return total housing units and total population from the 2010 Decennial Census, but, optionally, you can provide a different list of\n",
    "    valid variables for the 2010 Decennial Census SF1 API. (DECENNIALSF12010 in cenpy terms)\n",
    "    \"\"\"\n",
    "    valid_census_geog = ['tract', 'block group']\n",
    "    if census_geog not in valid_census_geog:\n",
    "        raise ValueError(f\"census_geog must be one of [{'|'}.join(valid_census_geog)]\")\n",
    "    \n",
    "    predicate_xref = {\n",
    "        'int': int,\n",
    "        'float': float\n",
    "    }\n",
    "\n",
    "    api_con = cenpy.products.APIConnection(acs_product,apikey=CENSUS_API_KEY)\n",
    "    df = api_con.query(cols=var_list,geo_unit=census_geog, geo_filter={'state': state, 'county': county})    \n",
    "\n",
    "    geoid_cols = ['state', 'county', 'tract']\n",
    "    if census_geog == 'block group':\n",
    "        geoid_cols.append('block group')\n",
    "\n",
    "    def concat_geoid(row):\n",
    "        parts = [row.loc[c] for c in geoid_cols]\n",
    "        return ''.join(parts)\n",
    "    df['geoid'] = df.apply(concat_geoid,result_type='expand',axis=1) \n",
    "    predicates = api_con.variables['predicateType']\n",
    "    # cenpy returns numeric values as strings so we need to convert them\n",
    "    # use the API's predicateType value to distinguish between int and float values.\n",
    "    for var in var_list:\n",
    "        vtype = predicates.loc[var]\n",
    "        df[var] = df[var].astype(predicate_xref.get(vtype,'object')) \n",
    "    return df.drop(geoid_cols,axis='columns').rename(columns={'geoid': census_geog}).set_index(census_geog)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "VALID_ACS_PRODUCT = re.compile('^ACS(DP|DT|ST)5Y20\\d{2}$') # doesn't actually validate that it's a valid ACS year\n",
    "def _validate_cenpy_code(code):\n",
    "    if not VALID_ACS_PRODUCT.match(code):\n",
    "        return False\n",
    "    try: # since the format doesn't test the actual year, make sure it's in Cenpy\n",
    "        _ = cenpy.explorer.available().loc[code]\n",
    "    except KeyError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def aggregate_acs(acs_product, var_list, weight_factor, census_geog='tract'):\n",
    "    \"\"\"Given the `cenpy` code for a Census data product\"\"\"\n",
    "    \n",
    "    valid_census_geog = ['tract', 'block group']\n",
    "    if census_geog not in valid_census_geog:\n",
    "        raise ValueError(f\"census_geog must be one of [{'|'}.join(valid_census_geog)]\")\n",
    "    \n",
    "    # do some validation\n",
    "    if type(weight_factor) is not pd.Series or len(weight_factor.index.names) != 2 or weight_factor.index.names[0] != census_geog:\n",
    "        raise ValueError(f\"weight_factor should be a multi-indexed pandas.Series with its first part called '{census_geog}'\")\n",
    "        \n",
    "    if not _validate_cenpy_code(acs_product):\n",
    "        raise ValueError(\"invalid acs_product code\")\n",
    "\n",
    "    # this is an incomplete check on valid variables in var_list\n",
    "    # it will catch margin of error but not percents, they have a less obvious pattern\n",
    "    if len(var_list) != len(list(filter(lambda x: x[-1] == 'E',var_list))):\n",
    "        raise ValueError(\"invalid variables in var_list\") \n",
    "        \n",
    "    agg_col = weight_factor.index.names[-1] # save the name of the 'custom geography'\n",
    "    state_county = _extract_unique_counties(weight_factor.index.get_level_values(census_geog))\n",
    "    geographies = []\n",
    "    for idx,row in state_county.iterrows():\n",
    "        geographies.append(unit_data_for_county(row['state'], row['county'], acs_product, var_list, census_geog))\n",
    "    \n",
    "    geographies = pd.concat(geographies)\n",
    "    factored = {}\n",
    "    for col in var_list:\n",
    "        factored[col] = geographies[col] * weight_factor\n",
    "    factored = pd.DataFrame(factored)\n",
    "    return factored.reset_index().drop(columns=[census_geog]).groupby(agg_col).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example\n",
    "\n",
    "To do something like what John did, we need to identify the variables. If you know the right table, you can get the variable list from the Census API. To keep things smaller, we'll just use table B02001: Race, equivalent to Decennial Census table P3. \n",
    "\n",
    "* [B02001 variables (HTML)](https://api.census.gov/data/2018/acs/acs5/groups/B02001.html)\n",
    "* [B02001 variables (JSON)](https://api.census.gov/data/2018/acs/acs5/groups/B02001.json)\n",
    "\n",
    "After reviewing that, we'll make `variables` to organize the data we want to actually aggregate, and to help us label the columns later.\n",
    "\n",
    "B02001 is from the \"Detailed Tables\" dataset and we want the most recent data, so we'll use the Cenpy product code `ACSDT5Y2018`\n",
    "\n",
    "Earlier, we created `weight_factors` telling us how tract-level population and housing units are divided across the police districts. Since data in B02001 counts people, not housing units, we pass in the `pfactor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>White alone</th>\n",
       "      <th>Black or African American alone</th>\n",
       "      <th>American Indian and Alaska Native alone</th>\n",
       "      <th>Asian alone</th>\n",
       "      <th>Native Hawaiian and Other Pacific Islander alone</th>\n",
       "      <th>Some other race alone</th>\n",
       "      <th>Two or more races</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77629.265110</td>\n",
       "      <td>43213.542030</td>\n",
       "      <td>14630.182002</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>16301.704815</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>795.831092</td>\n",
       "      <td>2484.005172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99557.424294</td>\n",
       "      <td>22182.806855</td>\n",
       "      <td>65941.914918</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>6951.802179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1171.083467</td>\n",
       "      <td>3042.816876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73030.676642</td>\n",
       "      <td>3248.129496</td>\n",
       "      <td>67071.548905</td>\n",
       "      <td>297.769399</td>\n",
       "      <td>775.092493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>516.225620</td>\n",
       "      <td>1121.910729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119538.024440</td>\n",
       "      <td>39892.433519</td>\n",
       "      <td>73459.014347</td>\n",
       "      <td>120.230601</td>\n",
       "      <td>292.105329</td>\n",
       "      <td>18.035817</td>\n",
       "      <td>4031.060018</td>\n",
       "      <td>1725.144810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>73343.956343</td>\n",
       "      <td>3216.005597</td>\n",
       "      <td>68914.948881</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>277.001866</td>\n",
       "      <td>724.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>85782.999955</td>\n",
       "      <td>1465.410740</td>\n",
       "      <td>82380.182518</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>43.964183</td>\n",
       "      <td>496.314929</td>\n",
       "      <td>1010.127585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>57165.536827</td>\n",
       "      <td>1886.414072</td>\n",
       "      <td>52792.652227</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>79.997165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1770.473363</td>\n",
       "      <td>533.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>250872.000000</td>\n",
       "      <td>118047.000000</td>\n",
       "      <td>49103.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>3209.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>72622.000000</td>\n",
       "      <td>6821.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>161499.840280</td>\n",
       "      <td>72435.314747</td>\n",
       "      <td>15567.225660</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>31196.309976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38057.827504</td>\n",
       "      <td>2949.162393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>110641.958556</td>\n",
       "      <td>42405.617779</td>\n",
       "      <td>35991.018397</td>\n",
       "      <td>464.563936</td>\n",
       "      <td>260.902611</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>29896.056142</td>\n",
       "      <td>1609.799691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>69557.899290</td>\n",
       "      <td>5923.098274</td>\n",
       "      <td>54500.685775</td>\n",
       "      <td>52.601987</td>\n",
       "      <td>525.553541</td>\n",
       "      <td>52.808337</td>\n",
       "      <td>7022.397812</td>\n",
       "      <td>1480.753565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>131641.693036</td>\n",
       "      <td>76884.773859</td>\n",
       "      <td>23480.176666</td>\n",
       "      <td>479.475103</td>\n",
       "      <td>11651.492939</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>15140.657110</td>\n",
       "      <td>3922.117359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119971.993331</td>\n",
       "      <td>91735.176073</td>\n",
       "      <td>7484.953930</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>5044.187183</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>10257.727140</td>\n",
       "      <td>5037.949004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>57663.731896</td>\n",
       "      <td>3100.276959</td>\n",
       "      <td>50396.495775</td>\n",
       "      <td>30.358974</td>\n",
       "      <td>147.851770</td>\n",
       "      <td>39.191663</td>\n",
       "      <td>3410.343938</td>\n",
       "      <td>539.212817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>206520.370951</td>\n",
       "      <td>164862.277088</td>\n",
       "      <td>3440.559296</td>\n",
       "      <td>579.984923</td>\n",
       "      <td>13195.873426</td>\n",
       "      <td>83.610405</td>\n",
       "      <td>17327.621928</td>\n",
       "      <td>7030.443884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>144452.695424</td>\n",
       "      <td>97332.201883</td>\n",
       "      <td>5313.349901</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>18349.818480</td>\n",
       "      <td>113.057587</td>\n",
       "      <td>17168.688198</td>\n",
       "      <td>5943.579374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>128228.000000</td>\n",
       "      <td>99438.000000</td>\n",
       "      <td>9270.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>14349.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>3484.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>214588.000000</td>\n",
       "      <td>175264.000000</td>\n",
       "      <td>13430.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>14244.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>3436.000000</td>\n",
       "      <td>7553.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>96078.815981</td>\n",
       "      <td>65276.716707</td>\n",
       "      <td>9510.861985</td>\n",
       "      <td>197.048426</td>\n",
       "      <td>13442.116223</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>3792.779661</td>\n",
       "      <td>3818.292978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>108159.000000</td>\n",
       "      <td>41214.000000</td>\n",
       "      <td>62637.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1587.000000</td>\n",
       "      <td>1917.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>145292.184019</td>\n",
       "      <td>83031.283293</td>\n",
       "      <td>27715.138015</td>\n",
       "      <td>608.951574</td>\n",
       "      <td>20452.883777</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7686.220339</td>\n",
       "      <td>5784.707022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>196822.000000</td>\n",
       "      <td>96951.000000</td>\n",
       "      <td>29634.000000</td>\n",
       "      <td>854.000000</td>\n",
       "      <td>3490.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>60093.000000</td>\n",
       "      <td>5761.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>27703.933625</td>\n",
       "      <td>24779.521029</td>\n",
       "      <td>201.090802</td>\n",
       "      <td>17.015077</td>\n",
       "      <td>1928.308094</td>\n",
       "      <td>11.332008</td>\n",
       "      <td>412.689874</td>\n",
       "      <td>353.976742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Total    White alone  Black or African American alone  \\\n",
       "dist_num                                                                  \n",
       "1          77629.265110   43213.542030                     14630.182002   \n",
       "2          99557.424294   22182.806855                     65941.914918   \n",
       "3          73030.676642    3248.129496                     67071.548905   \n",
       "4         119538.024440   39892.433519                     73459.014347   \n",
       "5          73343.956343    3216.005597                     68914.948881   \n",
       "6          85782.999955    1465.410740                     82380.182518   \n",
       "7          57165.536827    1886.414072                     52792.652227   \n",
       "8         250872.000000  118047.000000                     49103.000000   \n",
       "9         161499.840280   72435.314747                     15567.225660   \n",
       "10        110641.958556   42405.617779                     35991.018397   \n",
       "11         69557.899290    5923.098274                     54500.685775   \n",
       "12        131641.693036   76884.773859                     23480.176666   \n",
       "14        119971.993331   91735.176073                      7484.953930   \n",
       "15         57663.731896    3100.276959                     50396.495775   \n",
       "16        206520.370951  164862.277088                      3440.559296   \n",
       "17        144452.695424   97332.201883                      5313.349901   \n",
       "18        128228.000000   99438.000000                      9270.000000   \n",
       "19        214588.000000  175264.000000                     13430.000000   \n",
       "20         96078.815981   65276.716707                      9510.861985   \n",
       "22        108159.000000   41214.000000                     62637.000000   \n",
       "24        145292.184019   83031.283293                     27715.138015   \n",
       "25        196822.000000   96951.000000                     29634.000000   \n",
       "31         27703.933625   24779.521029                       201.090802   \n",
       "\n",
       "          American Indian and Alaska Native alone   Asian alone  \\\n",
       "dist_num                                                          \n",
       "1                                      195.000000  16301.704815   \n",
       "2                                      267.000000   6951.802179   \n",
       "3                                      297.769399    775.092493   \n",
       "4                                      120.230601    292.105329   \n",
       "5                                       56.000000    145.000000   \n",
       "6                                       61.000000    326.000000   \n",
       "7                                      103.000000     79.997165   \n",
       "8                                     1029.000000   3209.000000   \n",
       "9                                     1294.000000  31196.309976   \n",
       "10                                     464.563936    260.902611   \n",
       "11                                      52.601987    525.553541   \n",
       "12                                     479.475103  11651.492939   \n",
       "14                                     371.000000   5044.187183   \n",
       "15                                      30.358974    147.851770   \n",
       "16                                     579.984923  13195.873426   \n",
       "17                                     232.000000  18349.818480   \n",
       "18                                     227.000000  14349.000000   \n",
       "19                                     576.000000  14244.000000   \n",
       "20                                     197.048426  13442.116223   \n",
       "22                                      62.000000    733.000000   \n",
       "24                                     608.951574  20452.883777   \n",
       "25                                     854.000000   3490.000000   \n",
       "31                                      17.015077   1928.308094   \n",
       "\n",
       "          Native Hawaiian and Other Pacific Islander alone  \\\n",
       "dist_num                                                     \n",
       "1                                                 9.000000   \n",
       "2                                                 0.000000   \n",
       "3                                                 0.000000   \n",
       "4                                                18.035817   \n",
       "5                                                11.000000   \n",
       "6                                                43.964183   \n",
       "7                                                 0.000000   \n",
       "8                                                41.000000   \n",
       "9                                                 0.000000   \n",
       "10                                               14.000000   \n",
       "11                                               52.808337   \n",
       "12                                               83.000000   \n",
       "14                                               41.000000   \n",
       "15                                               39.191663   \n",
       "16                                               83.610405   \n",
       "17                                              113.057587   \n",
       "18                                                5.000000   \n",
       "19                                               85.000000   \n",
       "20                                               41.000000   \n",
       "22                                                9.000000   \n",
       "24                                               13.000000   \n",
       "25                                               39.000000   \n",
       "31                                               11.332008   \n",
       "\n",
       "          Some other race alone  Two or more races  \n",
       "dist_num                                            \n",
       "1                    795.831092        2484.005172  \n",
       "2                   1171.083467        3042.816876  \n",
       "3                    516.225620        1121.910729  \n",
       "4                   4031.060018        1725.144810  \n",
       "5                    277.001866         724.000000  \n",
       "6                    496.314929        1010.127585  \n",
       "7                   1770.473363         533.000000  \n",
       "8                  72622.000000        6821.000000  \n",
       "9                  38057.827504        2949.162393  \n",
       "10                 29896.056142        1609.799691  \n",
       "11                  7022.397812        1480.753565  \n",
       "12                 15140.657110        3922.117359  \n",
       "14                 10257.727140        5037.949004  \n",
       "15                  3410.343938         539.212817  \n",
       "16                 17327.621928        7030.443884  \n",
       "17                 17168.688198        5943.579374  \n",
       "18                  1455.000000        3484.000000  \n",
       "19                  3436.000000        7553.000000  \n",
       "20                  3792.779661        3818.292978  \n",
       "22                  1587.000000        1917.000000  \n",
       "24                  7686.220339        5784.707022  \n",
       "25                 60093.000000        5761.000000  \n",
       "31                   412.689874         353.976742  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables = {\n",
    "    'B02001_001E': \"Total\",\n",
    "    'B02001_002E': \"White alone\",\n",
    "    'B02001_003E': \"Black or African American alone\",\n",
    "    'B02001_004E': \"American Indian and Alaska Native alone\",\n",
    "    'B02001_005E': \"Asian alone\",\n",
    "    'B02001_006E': \"Native Hawaiian and Other Pacific Islander alone\",\n",
    "    'B02001_007E': \"Some other race alone\",\n",
    "    'B02001_008E': \"Two or more races\"\n",
    "}\n",
    "aggregated = aggregate_acs('ACSDT5Y2018', sorted(variables.keys()), weight_factors['pfactor'])\n",
    "aggregated.rename(columns=variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare aggregating tracts and aggregating blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>White alone</th>\n",
       "      <th>Black or African American alone</th>\n",
       "      <th>American Indian and Alaska Native alone</th>\n",
       "      <th>Asian alone</th>\n",
       "      <th>Native Hawaiian and Other Pacific Islander alone</th>\n",
       "      <th>Some other race alone</th>\n",
       "      <th>Two or more races</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77518.184824</td>\n",
       "      <td>43101.164616</td>\n",
       "      <td>14569.694895</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>16336.232762</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>799.544786</td>\n",
       "      <td>2507.547765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99608.251055</td>\n",
       "      <td>22207.242663</td>\n",
       "      <td>65970.095958</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>6951.802179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1169.293379</td>\n",
       "      <td>3042.816876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72123.647387</td>\n",
       "      <td>3200.132486</td>\n",
       "      <td>66110.920755</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>765.197821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>545.213200</td>\n",
       "      <td>1200.183124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120488.570633</td>\n",
       "      <td>39935.604901</td>\n",
       "      <td>74469.391199</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4001.000000</td>\n",
       "      <td>1646.574534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>71608.027434</td>\n",
       "      <td>3119.010619</td>\n",
       "      <td>67340.016814</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>695.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>85810.297186</td>\n",
       "      <td>1464.384480</td>\n",
       "      <td>82420.487240</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>1010.425466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>57046.079369</td>\n",
       "      <td>1867.808641</td>\n",
       "      <td>52676.388570</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>79.995595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1785.886564</td>\n",
       "      <td>533.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>250806.000000</td>\n",
       "      <td>117989.000000</td>\n",
       "      <td>49103.000000</td>\n",
       "      <td>1029.000000</td>\n",
       "      <td>3209.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>72614.000000</td>\n",
       "      <td>6821.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>161479.798731</td>\n",
       "      <td>72439.685440</td>\n",
       "      <td>15563.485361</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>31176.910816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38058.606857</td>\n",
       "      <td>2947.110256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>110655.160876</td>\n",
       "      <td>42455.537846</td>\n",
       "      <td>35976.338223</td>\n",
       "      <td>464.519934</td>\n",
       "      <td>256.677499</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>29874.584521</td>\n",
       "      <td>1613.502853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>69183.383519</td>\n",
       "      <td>5882.483310</td>\n",
       "      <td>54122.550033</td>\n",
       "      <td>47.131222</td>\n",
       "      <td>489.592834</td>\n",
       "      <td>49.709030</td>\n",
       "      <td>7035.904710</td>\n",
       "      <td>1556.012380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>132157.318598</td>\n",
       "      <td>77411.296564</td>\n",
       "      <td>23594.690757</td>\n",
       "      <td>483.348844</td>\n",
       "      <td>11676.344472</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>15039.846749</td>\n",
       "      <td>3868.791212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119785.507109</td>\n",
       "      <td>91332.114894</td>\n",
       "      <td>7653.905372</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>5009.246023</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>10319.205287</td>\n",
       "      <td>5059.035534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>57824.773279</td>\n",
       "      <td>3075.533540</td>\n",
       "      <td>50568.034823</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>42.290970</td>\n",
       "      <td>3452.913947</td>\n",
       "      <td>471.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>205561.238488</td>\n",
       "      <td>164165.657486</td>\n",
       "      <td>3436.182629</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>13109.360563</td>\n",
       "      <td>83.406855</td>\n",
       "      <td>17187.323016</td>\n",
       "      <td>6999.307938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>144774.268256</td>\n",
       "      <td>97426.992548</td>\n",
       "      <td>5318.134128</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>18409.000000</td>\n",
       "      <td>112.593145</td>\n",
       "      <td>17311.716841</td>\n",
       "      <td>5963.831595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>128228.000000</td>\n",
       "      <td>99438.000000</td>\n",
       "      <td>9270.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>14349.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>3484.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>214588.000000</td>\n",
       "      <td>175264.000000</td>\n",
       "      <td>13430.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>14244.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>3436.000000</td>\n",
       "      <td>7553.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>96090.840304</td>\n",
       "      <td>65278.228137</td>\n",
       "      <td>9523.155894</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>13445.809886</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>3788.965779</td>\n",
       "      <td>3816.680608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>102933.000000</td>\n",
       "      <td>37972.000000</td>\n",
       "      <td>61365.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1097.000000</td>\n",
       "      <td>1781.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>145280.159696</td>\n",
       "      <td>83029.771863</td>\n",
       "      <td>27702.844106</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>20449.190114</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7690.034221</td>\n",
       "      <td>5786.319392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>196822.000000</td>\n",
       "      <td>96951.000000</td>\n",
       "      <td>29634.000000</td>\n",
       "      <td>854.000000</td>\n",
       "      <td>3490.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>60093.000000</td>\n",
       "      <td>5761.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>25135.493256</td>\n",
       "      <td>22322.349965</td>\n",
       "      <td>200.683243</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1858.639437</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>409.960144</td>\n",
       "      <td>314.860467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Total    White alone  Black or African American alone  \\\n",
       "dist_num                                                                  \n",
       "1          77518.184824   43101.164616                     14569.694895   \n",
       "2          99608.251055   22207.242663                     65970.095958   \n",
       "3          72123.647387    3200.132486                     66110.920755   \n",
       "4         120488.570633   39935.604901                     74469.391199   \n",
       "5          71608.027434    3119.010619                     67340.016814   \n",
       "6          85810.297186    1464.384480                     82420.487240   \n",
       "7          57046.079369    1867.808641                     52676.388570   \n",
       "8         250806.000000  117989.000000                     49103.000000   \n",
       "9         161479.798731   72439.685440                     15563.485361   \n",
       "10        110655.160876   42455.537846                     35976.338223   \n",
       "11         69183.383519    5882.483310                     54122.550033   \n",
       "12        132157.318598   77411.296564                     23594.690757   \n",
       "14        119785.507109   91332.114894                      7653.905372   \n",
       "15         57824.773279    3075.533540                     50568.034823   \n",
       "16        205561.238488  164165.657486                      3436.182629   \n",
       "17        144774.268256   97426.992548                      5318.134128   \n",
       "18        128228.000000   99438.000000                      9270.000000   \n",
       "19        214588.000000  175264.000000                     13430.000000   \n",
       "20         96090.840304   65278.228137                      9523.155894   \n",
       "22        102933.000000   37972.000000                     61365.000000   \n",
       "24        145280.159696   83029.771863                     27702.844106   \n",
       "25        196822.000000   96951.000000                     29634.000000   \n",
       "31         25135.493256   22322.349965                       200.683243   \n",
       "\n",
       "          American Indian and Alaska Native alone   Asian alone  \\\n",
       "dist_num                                                          \n",
       "1                                      195.000000  16336.232762   \n",
       "2                                      267.000000   6951.802179   \n",
       "3                                      302.000000    765.197821   \n",
       "4                                      116.000000    302.000000   \n",
       "5                                       56.000000    145.000000   \n",
       "6                                       61.000000    326.000000   \n",
       "7                                      103.000000     79.995595   \n",
       "8                                     1029.000000   3209.000000   \n",
       "9                                     1294.000000  31176.910816   \n",
       "10                                     464.519934    256.677499   \n",
       "11                                      47.131222    489.592834   \n",
       "12                                     483.348844  11676.344472   \n",
       "14                                     371.000000   5009.246023   \n",
       "15                                      32.000000    183.000000   \n",
       "16                                     580.000000  13109.360563   \n",
       "17                                     232.000000  18409.000000   \n",
       "18                                     227.000000  14349.000000   \n",
       "19                                     576.000000  14244.000000   \n",
       "20                                     197.000000  13445.809886   \n",
       "22                                      62.000000    647.000000   \n",
       "24                                     609.000000  20449.190114   \n",
       "25                                     854.000000   3490.000000   \n",
       "31                                      17.000000   1858.639437   \n",
       "\n",
       "          Native Hawaiian and Other Pacific Islander alone  \\\n",
       "dist_num                                                     \n",
       "1                                                 9.000000   \n",
       "2                                                 0.000000   \n",
       "3                                                 0.000000   \n",
       "4                                                18.000000   \n",
       "5                                                11.000000   \n",
       "6                                                44.000000   \n",
       "7                                                 0.000000   \n",
       "8                                                41.000000   \n",
       "9                                                 0.000000   \n",
       "10                                               14.000000   \n",
       "11                                               49.709030   \n",
       "12                                               83.000000   \n",
       "14                                               41.000000   \n",
       "15                                               42.290970   \n",
       "16                                               83.406855   \n",
       "17                                              112.593145   \n",
       "18                                                5.000000   \n",
       "19                                               85.000000   \n",
       "20                                               41.000000   \n",
       "22                                                9.000000   \n",
       "24                                               13.000000   \n",
       "25                                               39.000000   \n",
       "31                                               12.000000   \n",
       "\n",
       "          Some other race alone  Two or more races  \n",
       "dist_num                                            \n",
       "1                    799.544786        2507.547765  \n",
       "2                   1169.293379        3042.816876  \n",
       "3                    545.213200        1200.183124  \n",
       "4                   4001.000000        1646.574534  \n",
       "5                    242.000000         695.000000  \n",
       "6                    484.000000        1010.425466  \n",
       "7                   1785.886564         533.000000  \n",
       "8                  72614.000000        6821.000000  \n",
       "9                  38058.606857        2947.110256  \n",
       "10                 29874.584521        1613.502853  \n",
       "11                  7035.904710        1556.012380  \n",
       "12                 15039.846749        3868.791212  \n",
       "14                 10319.205287        5059.035534  \n",
       "15                  3452.913947         471.000000  \n",
       "16                 17187.323016        6999.307938  \n",
       "17                 17311.716841        5963.831595  \n",
       "18                  1455.000000        3484.000000  \n",
       "19                  3436.000000        7553.000000  \n",
       "20                  3788.965779        3816.680608  \n",
       "22                  1097.000000        1781.000000  \n",
       "24                  7690.034221        5786.319392  \n",
       "25                 60093.000000        5761.000000  \n",
       "31                   409.960144         314.860467  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `blocks_with_data` was created in an example above\n",
    "bg_weight_factors = blocks_to_bgs(blocks_with_data,'dist_num',pop_column='P001001',hu_column='H001001')\n",
    "\n",
    "bg_aggregated = aggregate_acs('ACSDT5Y2018', sorted(variables.keys()), bg_weight_factors['pfactor'], 'block group')\n",
    "bg_aggregated.rename(columns=variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tract_total_pop</th>\n",
       "      <th>Total</th>\n",
       "      <th>White alone</th>\n",
       "      <th>Black or African American alone</th>\n",
       "      <th>American Indian and Alaska Native alone</th>\n",
       "      <th>Asian alone</th>\n",
       "      <th>Native Hawaiian and Other Pacific Islander alone</th>\n",
       "      <th>Some other race alone</th>\n",
       "      <th>Two or more races</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77,629.27</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99,557.42</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73,030.68</td>\n",
       "      <td>-1.26</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>nan</td>\n",
       "      <td>5.32</td>\n",
       "      <td>6.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119,538.02</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.36</td>\n",
       "      <td>-3.65</td>\n",
       "      <td>3.28</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>73,343.96</td>\n",
       "      <td>-2.42</td>\n",
       "      <td>-3.11</td>\n",
       "      <td>-2.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-14.46</td>\n",
       "      <td>-4.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>85,783.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-2.54</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>57,165.54</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>250,872.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>161,499.84</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>110,641.96</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>69,557.90</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>-11.61</td>\n",
       "      <td>-7.35</td>\n",
       "      <td>-6.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>131,641.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119,971.99</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>57,663.73</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>0.34</td>\n",
       "      <td>5.13</td>\n",
       "      <td>19.21</td>\n",
       "      <td>7.33</td>\n",
       "      <td>1.23</td>\n",
       "      <td>-14.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>206,520.37</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>-0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>144,452.70</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>128,228.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>214,588.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>96,078.82</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>108,159.00</td>\n",
       "      <td>-5.08</td>\n",
       "      <td>-8.54</td>\n",
       "      <td>-2.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-13.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-44.67</td>\n",
       "      <td>-7.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>145,292.18</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>196,822.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>27,703.93</td>\n",
       "      <td>-10.22</td>\n",
       "      <td>-11.01</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>5.57</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-12.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tract_total_pop  Total  White alone  \\\n",
       "dist_num                                        \n",
       "1               77,629.27  -0.14        -0.26   \n",
       "2               99,557.42   0.05         0.11   \n",
       "3               73,030.68  -1.26        -1.50   \n",
       "4              119,538.02   0.79         0.11   \n",
       "5               73,343.96  -2.42        -3.11   \n",
       "6               85,783.00   0.03        -0.07   \n",
       "7               57,165.54  -0.21        -1.00   \n",
       "8              250,872.00  -0.03        -0.05   \n",
       "9              161,499.84  -0.01         0.01   \n",
       "10             110,641.96   0.01         0.12   \n",
       "11              69,557.90  -0.54        -0.69   \n",
       "12             131,641.69   0.39         0.68   \n",
       "14             119,971.99  -0.16        -0.44   \n",
       "15              57,663.73   0.28        -0.80   \n",
       "16             206,520.37  -0.47        -0.42   \n",
       "17             144,452.70   0.22         0.10   \n",
       "18             128,228.00   0.00         0.00   \n",
       "19             214,588.00   0.00         0.00   \n",
       "20              96,078.82   0.01         0.00   \n",
       "22             108,159.00  -5.08        -8.54   \n",
       "24             145,292.18  -0.01        -0.00   \n",
       "25             196,822.00   0.00         0.00   \n",
       "31              27,703.93 -10.22       -11.01   \n",
       "\n",
       "          Black or African American alone  \\\n",
       "dist_num                                    \n",
       "1                                   -0.42   \n",
       "2                                    0.04   \n",
       "3                                   -1.45   \n",
       "4                                    1.36   \n",
       "5                                   -2.34   \n",
       "6                                    0.05   \n",
       "7                                   -0.22   \n",
       "8                                    0.00   \n",
       "9                                   -0.02   \n",
       "10                                  -0.04   \n",
       "11                                  -0.70   \n",
       "12                                   0.49   \n",
       "14                                   2.21   \n",
       "15                                   0.34   \n",
       "16                                  -0.13   \n",
       "17                                   0.09   \n",
       "18                                   0.00   \n",
       "19                                   0.00   \n",
       "20                                   0.13   \n",
       "22                                  -2.07   \n",
       "24                                  -0.04   \n",
       "25                                   0.00   \n",
       "31                                  -0.20   \n",
       "\n",
       "          American Indian and Alaska Native alone  Asian alone  \\\n",
       "dist_num                                                         \n",
       "1                                            0.00         0.21   \n",
       "2                                            0.00         0.00   \n",
       "3                                            1.40        -1.29   \n",
       "4                                           -3.65         3.28   \n",
       "5                                            0.00         0.00   \n",
       "6                                            0.00         0.00   \n",
       "7                                            0.00        -0.00   \n",
       "8                                            0.00         0.00   \n",
       "9                                            0.00        -0.06   \n",
       "10                                          -0.01        -1.65   \n",
       "11                                         -11.61        -7.35   \n",
       "12                                           0.80         0.21   \n",
       "14                                           0.00        -0.70   \n",
       "15                                           5.13        19.21   \n",
       "16                                           0.00        -0.66   \n",
       "17                                           0.00         0.32   \n",
       "18                                           0.00         0.00   \n",
       "19                                           0.00         0.00   \n",
       "20                                          -0.02         0.03   \n",
       "22                                           0.00       -13.29   \n",
       "24                                           0.01        -0.02   \n",
       "25                                           0.00         0.00   \n",
       "31                                          -0.09        -3.75   \n",
       "\n",
       "          Native Hawaiian and Other Pacific Islander alone  \\\n",
       "dist_num                                                     \n",
       "1                                                     0.00   \n",
       "2                                                      nan   \n",
       "3                                                      nan   \n",
       "4                                                    -0.20   \n",
       "5                                                     0.00   \n",
       "6                                                     0.08   \n",
       "7                                                      nan   \n",
       "8                                                     0.00   \n",
       "9                                                      nan   \n",
       "10                                                    0.00   \n",
       "11                                                   -6.23   \n",
       "12                                                    0.00   \n",
       "14                                                    0.00   \n",
       "15                                                    7.33   \n",
       "16                                                   -0.24   \n",
       "17                                                   -0.41   \n",
       "18                                                    0.00   \n",
       "19                                                    0.00   \n",
       "20                                                    0.00   \n",
       "22                                                    0.00   \n",
       "24                                                    0.00   \n",
       "25                                                    0.00   \n",
       "31                                                    5.57   \n",
       "\n",
       "          Some other race alone  Two or more races  \n",
       "dist_num                                            \n",
       "1                          0.46               0.94  \n",
       "2                         -0.15               0.00  \n",
       "3                          5.32               6.52  \n",
       "4                         -0.75              -4.77  \n",
       "5                        -14.46              -4.17  \n",
       "6                         -2.54               0.03  \n",
       "7                          0.86               0.00  \n",
       "8                         -0.01               0.00  \n",
       "9                          0.00              -0.07  \n",
       "10                        -0.07               0.23  \n",
       "11                         0.19               4.84  \n",
       "12                        -0.67              -1.38  \n",
       "14                         0.60               0.42  \n",
       "15                         1.23             -14.48  \n",
       "16                        -0.82              -0.44  \n",
       "17                         0.83               0.34  \n",
       "18                         0.00               0.00  \n",
       "19                         0.00               0.00  \n",
       "20                        -0.10              -0.04  \n",
       "22                       -44.67              -7.64  \n",
       "24                         0.05               0.03  \n",
       "25                         0.00               0.00  \n",
       "31                        -0.67             -12.42  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "pct_diff = (bg_aggregated - aggregated)/bg_aggregated * 100\n",
    "pct_diff.insert(0,'tract_total_pop',aggregated['B02001_001E'])\n",
    "pct_diff.rename(columns=variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see the percentage describerence between aggregating by block group and by tract. While in many cases, the difference isn't great, that there are some greater than 5% and a few >10% does give us pause. Not to mention more than 44% difference in district 22 for \"Some other race alone\"!\n",
    "\n",
    "While I didn't check it out systematically, the larger discrepancies mostly seem to go with either small populations (like \"Some other race alone\") or small total populations (like district 31, which is actually areas of unincorporated Cook County for which Chicago Police have some authority.)  That said, District 22 has a big discrepancy even in total population (-5%), and the population is close to the median.\n",
    "\n",
    "I don't know of any other source we could consult to see if one is \"more correct\" than another. Maybe it's worth trying something where the \"custom geography\" is a real Census geography like a county.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potentially interesting rollups.\n",
    "\n",
    "* [NYC Geographic Relationships](https://www1.nyc.gov/site/planning/planning-level/nyc-population/nyc-population-geographic-relationships.page) Neighborhood Tabulation Areas are built from Census tracts, so alignment is straightforward -- but people are interested in Community Districts. Is there an xref from NTA to CD?\n",
    "* Seattle had some that were from tracts\n",
    "* Chicago Community Areas of course -- also from tracts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
