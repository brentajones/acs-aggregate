{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Race by District (with Margin of Error)\n",
    "\n",
    "This workbook demonstrates how to aggregate ACS data where some estimates may be less reliable, typically because they are for small subgroups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cenpy                  # https://pypi.org/project/cenpy/ \n",
    "import census_data_aggregator # https://pypi.org/project/census-data-aggregator/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B03002_001E</th>\n",
       "      <td>Estimate!!Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_002E</th>\n",
       "      <td>Estimate!!Total!!Not Hispanic or Latino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_003E</th>\n",
       "      <td>Estimate!!Total!!Not Hispanic or Latino!!White alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_004E</th>\n",
       "      <td>Estimate!!Total!!Not Hispanic or Latino!!Black or African American alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_005E</th>\n",
       "      <td>Estimate!!Total!!Not Hispanic or Latino!!American Indian and Alaska Native alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_006E</th>\n",
       "      <td>Estimate!!Total!!Not Hispanic or Latino!!Asian alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_007E</th>\n",
       "      <td>Estimate!!Total!!Not Hispanic or Latino!!Native Hawaiian and Other Pacific Islander alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_008E</th>\n",
       "      <td>Estimate!!Total!!Not Hispanic or Latino!!Some other race alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_009E</th>\n",
       "      <td>Estimate!!Total!!Not Hispanic or Latino!!Two or more races</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_010E</th>\n",
       "      <td>Estimate!!Total!!Not Hispanic or Latino!!Two or more races!!Two races including Some other race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_011E</th>\n",
       "      <td>Estimate!!Total!!Not Hispanic or Latino!!Two or more races!!Two races excluding Some other race, and three or more races</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_012E</th>\n",
       "      <td>Estimate!!Total!!Hispanic or Latino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_013E</th>\n",
       "      <td>Estimate!!Total!!Hispanic or Latino!!White alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_014E</th>\n",
       "      <td>Estimate!!Total!!Hispanic or Latino!!Black or African American alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_015E</th>\n",
       "      <td>Estimate!!Total!!Hispanic or Latino!!American Indian and Alaska Native alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_016E</th>\n",
       "      <td>Estimate!!Total!!Hispanic or Latino!!Asian alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_017E</th>\n",
       "      <td>Estimate!!Total!!Hispanic or Latino!!Native Hawaiian and Other Pacific Islander alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_018E</th>\n",
       "      <td>Estimate!!Total!!Hispanic or Latino!!Some other race alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_019E</th>\n",
       "      <td>Estimate!!Total!!Hispanic or Latino!!Two or more races</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_020E</th>\n",
       "      <td>Estimate!!Total!!Hispanic or Latino!!Two or more races!!Two races including Some other race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03002_021E</th>\n",
       "      <td>Estimate!!Total!!Hispanic or Latino!!Two or more races!!Two races excluding Some other race, and three or more races</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                label\n",
       "B03002_001E                                                                                                           Estimate!!Total\n",
       "B03002_002E                                                                                   Estimate!!Total!!Not Hispanic or Latino\n",
       "B03002_003E                                                                      Estimate!!Total!!Not Hispanic or Latino!!White alone\n",
       "B03002_004E                                                  Estimate!!Total!!Not Hispanic or Latino!!Black or African American alone\n",
       "B03002_005E                                          Estimate!!Total!!Not Hispanic or Latino!!American Indian and Alaska Native alone\n",
       "B03002_006E                                                                      Estimate!!Total!!Not Hispanic or Latino!!Asian alone\n",
       "B03002_007E                                 Estimate!!Total!!Not Hispanic or Latino!!Native Hawaiian and Other Pacific Islander alone\n",
       "B03002_008E                                                            Estimate!!Total!!Not Hispanic or Latino!!Some other race alone\n",
       "B03002_009E                                                                Estimate!!Total!!Not Hispanic or Latino!!Two or more races\n",
       "B03002_010E                           Estimate!!Total!!Not Hispanic or Latino!!Two or more races!!Two races including Some other race\n",
       "B03002_011E  Estimate!!Total!!Not Hispanic or Latino!!Two or more races!!Two races excluding Some other race, and three or more races\n",
       "B03002_012E                                                                                       Estimate!!Total!!Hispanic or Latino\n",
       "B03002_013E                                                                          Estimate!!Total!!Hispanic or Latino!!White alone\n",
       "B03002_014E                                                      Estimate!!Total!!Hispanic or Latino!!Black or African American alone\n",
       "B03002_015E                                              Estimate!!Total!!Hispanic or Latino!!American Indian and Alaska Native alone\n",
       "B03002_016E                                                                          Estimate!!Total!!Hispanic or Latino!!Asian alone\n",
       "B03002_017E                                     Estimate!!Total!!Hispanic or Latino!!Native Hawaiian and Other Pacific Islander alone\n",
       "B03002_018E                                                                Estimate!!Total!!Hispanic or Latino!!Some other race alone\n",
       "B03002_019E                                                                    Estimate!!Total!!Hispanic or Latino!!Two or more races\n",
       "B03002_020E                               Estimate!!Total!!Hispanic or Latino!!Two or more races!!Two races including Some other race\n",
       "B03002_021E      Estimate!!Total!!Hispanic or Latino!!Two or more races!!Two races excluding Some other race, and three or more races"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs = cenpy.products.APIConnection('ACSDT5Y2018')\n",
    "\n",
    "# Refresh our memory on the variable codes for various columns in the race tables\n",
    "pd.set_option('display.max_colwidth',None)\n",
    "acs.varslike('B03002_*')[['label']].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make something to help us use friendlier names for the columns\n",
    "# Use an ordered dict to ensure that things between estimate and MOE cols stay in sync\n",
    "from collections import OrderedDict\n",
    "race_cols = OrderedDict([\n",
    "    ('B03002_001E', 'total'),\n",
    "    ('B03002_003E', 'nh_white'),\n",
    "    ('B03002_004E', 'nh_black'),\n",
    "    ('B03002_005E', 'nh_amerind'),\n",
    "    ('B03002_006E', 'nh_asian'),\n",
    "    ('B03002_007E', 'nh_nhpi'),\n",
    "    ('B03002_008E', 'nh_some_other'),\n",
    "    ('B03002_009E', 'nh_twoplus'),\n",
    "    ('B03002_012E', 'hispanic')\n",
    "])\n",
    "moe_cols = OrderedDict((k.replace('E','M'),v+\"_moe\") for k,v in race_cols.items())\n",
    "query_cols = ['GEO_ID'] + list(race_cols.keys()) + list(moe_cols.keys())\n",
    "county_race = acs.query(query_cols,'county')\n",
    "for k in query_cols[1:]: # cenpy doesn't cast estimates to integer so we have to handle that.\n",
    "    county_race[k] = county_race[k].astype(int)\n",
    "county_race = county_race.rename(columns=race_cols).rename(columns=moe_cols)\n",
    "\n",
    "# a Margin of Error value of -555555555 \"indicates that the estimate is controlled. \n",
    "# A statistical test for sampling variability is not appropriate.\"\n",
    "# The math doesn't work with that value, so replace those with 0\n",
    "county_race = county_race.replace(-555555555,0) \n",
    "county_race = county_race.drop(['state', 'county'], axis='columns') # API gives us those but we don't need them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join our crosswalk to the ACS data\n",
    "xref = pd.read_csv('county_district_xref.csv',index_col='geoid', usecols=['geoid','state', 'district'])\n",
    "joined = xref.join(county_race.set_index('GEO_ID'))# xref\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper function so that we can sum more than one estimate/moe pair in a given data frame\n",
    "def sum_with_moe(df, *column_pairs):\n",
    "    \"\"\"Given a data frame and a list of one or more tuples representing estimate/error pairs,\n",
    "       return a dictionary where each key is one of the values from column pairs and the corresponding\n",
    "       value is the approximate sum, or approximate error for the sum.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for est,err in column_pairs:\n",
    "        tuples = [tuple(x) for x in df[[est,err]].to_numpy()]\n",
    "        est_sum, err_sum = census_data_aggregator.approximate_sum(*tuples)\n",
    "        result[est] = est_sum\n",
    "        result[err] = err_sum\n",
    "    return result\n",
    "\n",
    "def compute_single_cv(est,moe):\n",
    "    se = moe/1.645 # assumes normal distribution\n",
    "    cv = se/est*100\n",
    "    return cv\n",
    "\n",
    "def compute_cvs(df, *column_pairs):\n",
    "    \"\"\"Given a data frame and a list of one or more tuples representing estimate/error pairs,\n",
    "       return a new DataFrame where each column represents the CV for one of the pairs.\n",
    "       Columns in the new DataFrame will be named by appending \"_cv\" to the first value\n",
    "       in each column_pair.\n",
    "    \"\"\"\n",
    "    cvs = []\n",
    "    for est,moe in column_pairs:\n",
    "        cv = df[[est,moe]].apply(lambda x: compute_single_cv(x[est],x[moe]),axis=1)\n",
    "        cv.name = f\"{est}_cv\"\n",
    "        cvs.append(cv)\n",
    "    return pd.concat(cvs,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>total</th>\n",
       "      <th>total_moe</th>\n",
       "      <th>nh_white</th>\n",
       "      <th>nh_white_moe</th>\n",
       "      <th>nh_black</th>\n",
       "      <th>nh_black_moe</th>\n",
       "      <th>nh_amerind</th>\n",
       "      <th>nh_amerind_moe</th>\n",
       "      <th>nh_asian</th>\n",
       "      <th>nh_asian_moe</th>\n",
       "      <th>nh_nhpi</th>\n",
       "      <th>nh_nhpi_moe</th>\n",
       "      <th>nh_some_other</th>\n",
       "      <th>nh_some_other_moe</th>\n",
       "      <th>nh_twoplus</th>\n",
       "      <th>nh_twoplus_moe</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>hispanic_moe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Middle</td>\n",
       "      <td>1151252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684038</td>\n",
       "      <td>454.9</td>\n",
       "      <td>382206</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>3308</td>\n",
       "      <td>396.8</td>\n",
       "      <td>18388</td>\n",
       "      <td>533.3</td>\n",
       "      <td>205</td>\n",
       "      <td>143.7</td>\n",
       "      <td>1551</td>\n",
       "      <td>479.4</td>\n",
       "      <td>20799</td>\n",
       "      <td>1337.3</td>\n",
       "      <td>40757</td>\n",
       "      <td>148.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Northern</td>\n",
       "      <td>2870454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1999982</td>\n",
       "      <td>585.5</td>\n",
       "      <td>628466</td>\n",
       "      <td>1964.2</td>\n",
       "      <td>12469</td>\n",
       "      <td>846.8</td>\n",
       "      <td>35008</td>\n",
       "      <td>1034.5</td>\n",
       "      <td>1169</td>\n",
       "      <td>223.0</td>\n",
       "      <td>4155</td>\n",
       "      <td>918.7</td>\n",
       "      <td>50506</td>\n",
       "      <td>2237.2</td>\n",
       "      <td>138699</td>\n",
       "      <td>193.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Southern</td>\n",
       "      <td>842974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>512710</td>\n",
       "      <td>370.5</td>\n",
       "      <td>275065</td>\n",
       "      <td>1002.8</td>\n",
       "      <td>7466</td>\n",
       "      <td>537.9</td>\n",
       "      <td>10540</td>\n",
       "      <td>583.5</td>\n",
       "      <td>147</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1797</td>\n",
       "      <td>566.0</td>\n",
       "      <td>11559</td>\n",
       "      <td>1097.3</td>\n",
       "      <td>23690</td>\n",
       "      <td>294.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>738516</td>\n",
       "      <td>564.0</td>\n",
       "      <td>450754</td>\n",
       "      <td>677.2</td>\n",
       "      <td>22817</td>\n",
       "      <td>730.1</td>\n",
       "      <td>103506</td>\n",
       "      <td>1448.5</td>\n",
       "      <td>45617</td>\n",
       "      <td>998.2</td>\n",
       "      <td>8544</td>\n",
       "      <td>395.9</td>\n",
       "      <td>1459</td>\n",
       "      <td>515.6</td>\n",
       "      <td>54633</td>\n",
       "      <td>1880.2</td>\n",
       "      <td>51186</td>\n",
       "      <td>257.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>6946685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3825886</td>\n",
       "      <td>1206.2</td>\n",
       "      <td>286614</td>\n",
       "      <td>2527.9</td>\n",
       "      <td>271946</td>\n",
       "      <td>1834.2</td>\n",
       "      <td>222477</td>\n",
       "      <td>2081.6</td>\n",
       "      <td>12523</td>\n",
       "      <td>561.2</td>\n",
       "      <td>9177</td>\n",
       "      <td>1290.8</td>\n",
       "      <td>154750</td>\n",
       "      <td>3919.1</td>\n",
       "      <td>2163312</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  district    total  total_moe  nh_white  nh_white_moe  nh_black  \\\n",
       "0  Alabama    Middle  1151252        0.0    684038         454.9    382206   \n",
       "1  Alabama  Northern  2870454        0.0   1999982         585.5    628466   \n",
       "2  Alabama  Southern   842974        0.0    512710         370.5    275065   \n",
       "3   Alaska    Alaska   738516      564.0    450754         677.2     22817   \n",
       "4  Arizona   Arizona  6946685        0.0   3825886        1206.2    286614   \n",
       "\n",
       "   nh_black_moe  nh_amerind  nh_amerind_moe  nh_asian  nh_asian_moe  nh_nhpi  \\\n",
       "0        1223.0        3308           396.8     18388         533.3      205   \n",
       "1        1964.2       12469           846.8     35008        1034.5     1169   \n",
       "2        1002.8        7466           537.9     10540         583.5      147   \n",
       "3         730.1      103506          1448.5     45617         998.2     8544   \n",
       "4        2527.9      271946          1834.2    222477        2081.6    12523   \n",
       "\n",
       "   nh_nhpi_moe  nh_some_other  nh_some_other_moe  nh_twoplus  nh_twoplus_moe  \\\n",
       "0        143.7           1551              479.4       20799          1337.3   \n",
       "1        223.0           4155              918.7       50506          2237.2   \n",
       "2        103.0           1797              566.0       11559          1097.3   \n",
       "3        395.9           1459              515.6       54633          1880.2   \n",
       "4        561.2           9177             1290.8      154750          3919.1   \n",
       "\n",
       "   hispanic  hispanic_moe  \n",
       "0     40757         148.2  \n",
       "1    138699         193.9  \n",
       "2     23690         294.9  \n",
       "3     51186         257.9  \n",
       "4   2163312           0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum the counties\n",
    "sums = []\n",
    "\n",
    "for (state, district), df in joined.groupby(['state', 'district']):\n",
    "    tuples = zip(race_cols.values(), moe_cols.values())  # we've renamed the columns to the values of those dicts\n",
    "    d = sum_with_moe(df, *tuples)\n",
    "    d['state'] = state\n",
    "    d['district'] = district\n",
    "    sums.append(d)\n",
    "\n",
    "race_by_district_base = pd.DataFrame(sums)    \n",
    "\n",
    "cols = list(race_by_district_base.columns) # for review purposes, it will be nice to have our grouping values at the front\n",
    "cols.remove('state') # so take them out\n",
    "cols.remove('district')\n",
    "cols = ['state', 'district'] + cols # put them where we want them\n",
    "race_by_district_base = race_by_district_base[cols]\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "race_by_district_base.head() # how does that look?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now what?\n",
    "\n",
    "Having aggregated margins of error enables two things: to test whether any given estimate is \"reliable\", and to test whether any two values are *significantly* different.  \n",
    "\n",
    "For now, we'll defer checking for \"significant difference,\" since I didn't feel like fishing around for pairs to compare. I'll just say that the LA Times DataDesk team has a python library which encapsulates the [statistical difference test](https://github.com/datadesk/census-error-analyzer#test-statistical-difference), so you might want to use that instead of re-implementing it. \n",
    "\n",
    "\n",
    "Testing reliability involves computing the Coefficient of Variation (CV). There are no hard and fast rules, but, as documented in this [Tufts GIS tutorial](http://sites.tufts.edu/gis/files/2013/11/Amercian-Community-Survey_Margin-of-error-tutorial.pdf), here are two rules of thumb about how to proceed with a given CV.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Source</th>\n",
    "        <th>High reliability</th>\n",
    "        <th>Medium \"be careful\"</th>\n",
    "        <th>Low \"use extreme caution\"</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Census Bureau</td>\n",
    "        <td>CV &lt;15%</td>        \n",
    "        <td>CV 15-30%</td>\n",
    "        <td>CV &gt;30%</td>        \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>ESRI</td>\n",
    "        <td>CV &lt;12%</td>        \n",
    "        <td>CV 12-40%</td>\n",
    "        <td>CV &gt;40%</td>        \n",
    "    </tr>\n",
    "</table>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>total_cv</th>\n",
       "      <th>nh_white_cv</th>\n",
       "      <th>nh_black_cv</th>\n",
       "      <th>nh_amerind_cv</th>\n",
       "      <th>nh_asian_cv</th>\n",
       "      <th>nh_nhpi_cv</th>\n",
       "      <th>nh_some_other_cv</th>\n",
       "      <th>nh_twoplus_cv</th>\n",
       "      <th>hispanic_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Middle</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>42.6</td>\n",
       "      <td>18.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Northern</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>11.6</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Southern</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>42.6</td>\n",
       "      <td>19.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>21.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  district  total_cv  nh_white_cv  nh_black_cv  nh_amerind_cv  \\\n",
       "0  Alabama    Middle       0.0          0.0          0.2            7.3   \n",
       "1  Alabama  Northern       0.0          0.0          0.2            4.1   \n",
       "2  Alabama  Southern       0.0          0.0          0.2            4.4   \n",
       "3   Alaska    Alaska       0.0          0.1          1.9            0.9   \n",
       "4  Arizona   Arizona       0.0          0.0          0.5            0.4   \n",
       "\n",
       "   nh_asian_cv  nh_nhpi_cv  nh_some_other_cv  nh_twoplus_cv  hispanic_cv  \n",
       "0          1.8        42.6              18.8            3.9          0.2  \n",
       "1          1.8        11.6              13.4            2.7          0.1  \n",
       "2          3.4        42.6              19.1            5.8          0.8  \n",
       "3          1.3         2.8              21.5            2.1          0.3  \n",
       "4          0.6         2.7               8.6            1.5          0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples = zip(race_cols.values(), moe_cols.values())  # again, get pairs of column names for estimate/moe\n",
    "race_district_cvs = compute_cvs(race_by_district_base,*tuples)\n",
    "race_district_cvs.insert(0,'state',race_by_district_base['state'])       # the indexes will be aligned, so we can just\n",
    "race_district_cvs.insert(1,'district',race_by_district_base['district']) # insert the group labels\n",
    "race_district_cvs.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## What have we got\n",
    " \n",
    "Typically, you'd probably just consult the CV matrix for specific values before you went too far using them, but for our purposes, let's iterate through and see where we should take care. You'll see that the most common cases of caution are for populations which tend to be small -- \"Native Hawaiian/Pacific Islander\" (except in Hawaii) and \"Some other race\" (which is most often used by Latinos, and so is often quite small among non-hispanic populations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviewing reliability of aggregated race by district\n",
      "\n",
      "Alabama Middle\n",
      "         nh_nhpi_cv - 42.6 - low reliability - use extreme caution\n",
      "   nh_some_other_cv - 18.8 - med reliability - use caution\n",
      "\n",
      "Alabama Northern\n",
      "  No warnings\n",
      "\n",
      "Alabama Southern\n",
      "         nh_nhpi_cv - 42.6 - low reliability - use extreme caution\n",
      "   nh_some_other_cv - 19.1 - med reliability - use caution\n",
      "\n",
      "Alaska\n",
      "   nh_some_other_cv - 21.5 - med reliability - use caution\n",
      "\n",
      "Arizona\n",
      "  No warnings\n",
      "\n",
      "Arkansas Eastern\n",
      "         nh_nhpi_cv - 28.5 - med reliability - use caution\n",
      "   nh_some_other_cv - 22.4 - med reliability - use caution\n",
      "\n",
      "Arkansas Western\n",
      "   nh_some_other_cv - 18.3 - med reliability - use caution\n",
      "\n",
      "California Central\n",
      "  No warnings\n",
      "\n",
      "California Eastern\n",
      "  No warnings\n",
      "\n",
      "California Northern\n",
      "  No warnings\n",
      "\n",
      "California Southern\n",
      "  No warnings\n",
      "\n",
      "Colorado\n",
      "  No warnings\n",
      "\n",
      "Connecticut\n",
      "         nh_nhpi_cv - 18.2 - med reliability - use caution\n",
      "\n",
      "Delaware\n",
      "         nh_nhpi_cv - 18.7 - med reliability - use caution\n",
      "\n",
      "District of Columbia\n",
      "         nh_nhpi_cv - 16.3 - med reliability - use caution\n",
      "\n",
      "Florida Middle\n",
      "  No warnings\n",
      "\n",
      "Florida Northern\n",
      "  No warnings\n",
      "\n",
      "Florida Southern\n",
      "  No warnings\n",
      "\n",
      "Georgia Middle\n",
      "         nh_nhpi_cv - 17.6 - med reliability - use caution\n",
      "\n",
      "Georgia Northern\n",
      "         nh_nhpi_cv - 16.2 - med reliability - use caution\n",
      "\n",
      "Georgia Southern\n",
      "  No warnings\n",
      "\n",
      "Hawaii\n",
      "  No warnings\n",
      "\n",
      "Idaho\n",
      "   nh_some_other_cv - 16.7 - med reliability - use caution\n",
      "\n",
      "Illinois Central\n",
      "         nh_nhpi_cv - 20.0 - med reliability - use caution\n",
      "\n",
      "Illinois Northern\n",
      "  No warnings\n",
      "\n",
      "Illinois Southern\n",
      "         nh_nhpi_cv - 27.0 - med reliability - use caution\n",
      "   nh_some_other_cv - 18.1 - med reliability - use caution\n",
      "\n",
      "Indiana Northern\n",
      "  No warnings\n",
      "\n",
      "Indiana Southern\n",
      "  No warnings\n",
      "\n",
      "Iowa Northern\n",
      "   nh_some_other_cv - 23.6 - med reliability - use caution\n",
      "\n",
      "Iowa Southern\n",
      "   nh_some_other_cv - 18.5 - med reliability - use caution\n",
      "\n",
      "Kansas\n",
      "  No warnings\n",
      "\n",
      "Kentucky Eastern\n",
      "         nh_nhpi_cv - 16.8 - med reliability - use caution\n",
      "   nh_some_other_cv - 16.4 - med reliability - use caution\n",
      "\n",
      "Kentucky Western\n",
      "  No warnings\n",
      "\n",
      "Louisiana Eastern\n",
      "         nh_nhpi_cv - 28.1 - med reliability - use caution\n",
      "\n",
      "Louisiana Middle\n",
      "         nh_nhpi_cv - 24.8 - med reliability - use caution\n",
      "   nh_some_other_cv - 26.6 - med reliability - use caution\n",
      "\n",
      "Louisiana Western\n",
      "  No warnings\n",
      "\n",
      "Maine\n",
      "         nh_nhpi_cv - 22.9 - med reliability - use caution\n",
      "   nh_some_other_cv - 18.4 - med reliability - use caution\n",
      "\n",
      "Maryland\n",
      "  No warnings\n",
      "\n",
      "Massachusetts\n",
      "  No warnings\n",
      "\n",
      "Michigan Eastern\n",
      "  No warnings\n",
      "\n",
      "Michigan Western\n",
      "  No warnings\n",
      "\n",
      "Minnesota\n",
      "  No warnings\n",
      "\n",
      "Mississippi northern\n",
      "         nh_nhpi_cv - 30.0 - med reliability - use caution\n",
      "   nh_some_other_cv - 24.4 - med reliability - use caution\n",
      "\n",
      "Mississippi southern\n",
      "         nh_nhpi_cv - 28.8 - med reliability - use caution\n",
      "   nh_some_other_cv - 16.1 - med reliability - use caution\n",
      "\n",
      "Missouri Eastern\n",
      "  No warnings\n",
      "\n",
      "Missouri Western\n",
      "  No warnings\n",
      "\n",
      "Montana\n",
      "   nh_some_other_cv - 25.0 - med reliability - use caution\n",
      "\n",
      "Nebraska\n",
      "  No warnings\n",
      "\n",
      "Nevada\n",
      "  No warnings\n",
      "\n",
      "New Hampshire\n",
      "         nh_nhpi_cv - 20.7 - med reliability - use caution\n",
      "   nh_some_other_cv - 18.0 - med reliability - use caution\n",
      "\n",
      "New Jersey\n",
      "  No warnings\n",
      "\n",
      "New Mexico\n",
      "  No warnings\n",
      "\n",
      "New York Eastern\n",
      "  No warnings\n",
      "\n",
      "New York Northern\n",
      "         nh_nhpi_cv - 15.1 - med reliability - use caution\n",
      "\n",
      "New York Southern\n",
      "  No warnings\n",
      "\n",
      "New York Western\n",
      "  No warnings\n",
      "\n",
      "North Carolina Eastern\n",
      "  No warnings\n",
      "\n",
      "North Carolina Middle\n",
      "  No warnings\n",
      "\n",
      "North Carolina Western\n",
      "  No warnings\n",
      "\n",
      "North Dakota\n",
      "         nh_nhpi_cv - 24.4 - med reliability - use caution\n",
      "   nh_some_other_cv - 30.5 - low reliability - use extreme caution\n",
      "\n",
      "Ohio Northern\n",
      "  No warnings\n",
      "\n",
      "Ohio Southern\n",
      "  No warnings\n",
      "\n",
      "Oklahoma Eastern\n",
      "   nh_some_other_cv - 16.7 - med reliability - use caution\n",
      "\n",
      "Oklahoma Northern\n",
      "  No warnings\n",
      "\n",
      "Oklahoma Western\n",
      "  No warnings\n",
      "\n",
      "Oregon\n",
      "  No warnings\n",
      "\n",
      "Pennsylvania Eastern\n",
      "  No warnings\n",
      "\n",
      "Pennsylvania Middle\n",
      "         nh_nhpi_cv - 17.8 - med reliability - use caution\n",
      "\n",
      "Pennsylvania Western\n",
      "  No warnings\n",
      "\n",
      "Puerto Rico\n",
      "      nh_amerind_cv - 53.5 - low reliability - use extreme caution\n",
      "        nh_asian_cv - 17.3 - med reliability - use caution\n",
      "         nh_nhpi_cv - 66.0 - low reliability - use extreme caution\n",
      "\n",
      "Rhode Island\n",
      "         nh_nhpi_cv - 22.4 - med reliability - use caution\n",
      "\n",
      "South Carolina\n",
      "  No warnings\n",
      "\n",
      "South Dakota\n",
      "         nh_nhpi_cv - 23.9 - med reliability - use caution\n",
      "   nh_some_other_cv - 33.3 - low reliability - use extreme caution\n",
      "\n",
      "Tennessee Eastern\n",
      "         nh_nhpi_cv - 18.3 - med reliability - use caution\n",
      "   nh_some_other_cv - 15.6 - med reliability - use caution\n",
      "\n",
      "Tennessee Middle\n",
      "  No warnings\n",
      "\n",
      "Tennessee Western\n",
      "         nh_nhpi_cv - 23.7 - med reliability - use caution\n",
      "   nh_some_other_cv - 18.4 - med reliability - use caution\n",
      "\n",
      "Texas Eastern\n",
      "  No warnings\n",
      "\n",
      "Texas Northern\n",
      "  No warnings\n",
      "\n",
      "Texas Southern\n",
      "  No warnings\n",
      "\n",
      "Texas Western\n",
      "  No warnings\n",
      "\n",
      "Utah\n",
      "  No warnings\n",
      "\n",
      "Vermont\n",
      "         nh_nhpi_cv - 25.5 - med reliability - use caution\n",
      "   nh_some_other_cv - 17.9 - med reliability - use caution\n",
      "\n",
      "Virginia Eastern\n",
      "  No warnings\n",
      "\n",
      "Virginia Western\n",
      "         nh_nhpi_cv - 18.4 - med reliability - use caution\n",
      "\n",
      "Washington Eastern\n",
      "   nh_some_other_cv - 20.6 - med reliability - use caution\n",
      "\n",
      "Washington Western\n",
      "  No warnings\n",
      "\n",
      "West Virginia Northern\n",
      "         nh_nhpi_cv - 46.7 - low reliability - use extreme caution\n",
      "   nh_some_other_cv - 18.6 - med reliability - use caution\n",
      "\n",
      "West Virginia Southern\n",
      "         nh_nhpi_cv - 30.5 - low reliability - use extreme caution\n",
      "   nh_some_other_cv - 22.1 - med reliability - use caution\n",
      "\n",
      "Wisconsin Eastern\n",
      "  No warnings\n",
      "\n",
      "Wisconsin Western\n",
      "         nh_nhpi_cv - 23.7 - med reliability - use caution\n",
      "\n",
      "Wyoming\n",
      "         nh_nhpi_cv - 32.5 - low reliability - use extreme caution\n",
      "   nh_some_other_cv - 34.3 - low reliability - use extreme caution\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reviewing reliability of aggregated race by district\\n\")\n",
    "for idx, row in race_district_cvs.iterrows():\n",
    "    warnings = []\n",
    "    for col in race_district_cvs.columns[2:]: # iterate all the non-label columns\n",
    "        if row[col] > 30:\n",
    "            warnings.append(f\"{col:>17} - {row[col]:.1f} - low reliability - use extreme caution\")\n",
    "        elif row[col] > 15:\n",
    "            warnings.append(f\"{col:>17} - {row[col]:.1f} - med reliability - use caution\")\n",
    "    if row['state'] == row['district']: # simplify for single-district states\n",
    "        print(f\"{row['state']}\")\n",
    "    else:\n",
    "        print(f\"{row['state']} {row['district']}\")\n",
    "    if len(warnings) == 0:\n",
    "        print(\"  No warnings\")\n",
    "    else:\n",
    "        for w in warnings:\n",
    "            print(f\"  {w}\")\n",
    "    print(\"\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
